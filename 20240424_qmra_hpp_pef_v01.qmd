---
title: "20240424_qmra_hpp_pef_v01"
format:
  html:
    embed-resources: true
  #docx:
    #number-sections: true
number-sections: true
editor: visual
execute: 
  error: false

bibliography: qmra_hpp_pef.bib
---

# **The effect of non-thermal processing on quantitative microbial risk assessment (QMRA)** {.unnumbered}

# Statement of purpose

The purpose of this QMRA is to estimate the impact of replacing conventional pasteurization processing with Pulsed Electric Fields or High-Pressure processing on the annual cases of illness caused by *Escherichia coli* after consuming "pasteurized" refrigerated, high-acidic fruit juice (from fresh fruits and not from concentrates). To accurately integrate the effect of processing (thermal, high-pressure, pulsed electric field) on the annual cases of illness, the approach of meta-analysis models (meta-regression) was used to quantitatively integrate the findings of many individual studies [@den_besten_meta-analysis_2012].

# Scope of QMRA

The scope of this QMRA is to include and assess the effects of the step of the juice production (i.e., "the juice is pumped to a holding tank") until it reaches the consumer (including the consumption of the fruit juice). The steps involved are: i., initial concentration; ii., inactivation using a means of processing; (iii., filling in bottles, no contamination there according to the HACCP examples from FDA) iii., consumer phase.

# A case study for juice treatment with HPP - Model definition

# Background

EFSA mentioned in Table 4 of @hazards_guidance_2020 e.g. Fruit juices HTST processed at 71.5°C for 15–30 s to reducing 5 Log10 reduction of E. coli O157:H7 and L. monocytogenes (Duan et al., 2011)

Since 1974, fruit juices have been implicated in more than 48 reported foodborne disease outbreaks, involving more than 5905 cases in various countries [@martinez-gonzales_safety_2016]. Outbreaks of Shiga-toxin-producing *E. coli* (STEC) have been associated with the consumption of unpasteurized apple cider and apple juice through outbreaks involved in the previous decades (@topalcengiz_thermal_2017). According to the FDA, *E. coli* and *Cryptosporidium parvum* are both pertinent microorganisms Although in most cases the growth of STEC will not occur, the microbial population will remain stable or slowly decline (depending on the fruit juice) for 3 to 84 days[@erickson_food_2007], the resistance to an acidic environment is strain-dependent (some strains can withstand low pH values) \[[\@kernou_inactivation_2023; \@mutaku_growth_2005; \@skandamis_modeling_2007; \@topalcengiz_thermal_2017; \@foster_acid_2001](spit%20the%20references%20here%20and%20add%20more%20text)\] (split the references and add more text) but also dependent if the cells are acid-adapted, which also increases the heat resistance [@topalcengiz_thermal_2017]. For some strains, there is no growth reported for pH below 4.0, while for others there is growth reported above the threshold of pH of 3.5 (this should be in one of the references above).

-   According to the FDA, The 5-log pathogen reduction must

    -   be accomplished for the microbe you identify as the "pertinent microorganism," which is the most resistant microorganism of public health significance that is likely to occur in the juice, e.g., *E. coli* O157:H7 (\>160 F and 6 seconds will provide a 5 log reduction, from the refrigerated apple juice HACCP example of FDA),

    -   take place in one facility just prior to or after packaging,([2](https://www.fda.gov/regulatory-information/search-fda-guidance-documents/guidance-industry-juice-hazard-analysis-critical-control-point-hazards-and-controls-guidance-first#ftn2)) and

    -   be applied directly to the juice, except for citrus juices.

The "pertinent microorganism" is the most resistant microorganism of public health significance that is likely to occur in the juice and is the pathogen that you must target for the 5-log pathogen reduction treatment (21 CFR 120.24(a)). By choosing the most resistant pathogen as your target, you are also treating the product for all other pathogens that are less resistant to the means of treatment.

One way to identify the pertinent microorganism for your juice is to consider whether there have been any illness outbreaks associated with this type of juice, and what microorganisms have caused the outbreaks. If certain pathogens have been demonstrated, i.e., through outbreaks, to be potential contaminants in certain juices, then the pertinent microorganism for your process typically should be one of these pathogens.

For example, Salmonella species have been the cause of several illness outbreaks related to orange juice and may be considered the "pertinent microorganism" for orange juice products. E. coli O157:H7, a bacterial pathogen, and Cryptosporidium parvum, a protozoan parasite, have both been the cause of outbreaks in untreated apple juice, and both should be identified as potential hazards in a hazard analysis for apple juice. Which of these two pathogens is determined to be the pertinent microorganism will depend upon which of the two is most resistant to the means of treatment, e.g., pasteurization, UV radiation, that you will use to achieve the 5-log reduction of pathogens that is required under the juice HACCP regulation. The pertinent microorganism for apple juice is discussed further in section V. C. 5.0.

Although Listeria monocytogenes has not been linked specifically to an illness outbreak from juice, it is ubiquitous in nature. For this reason, we recommend that Listeria monocytogenes be considered as a possible "pertinent microorganism" for juices that have not been associated with illness outbreaks caused by Salmonella species, E. coli O157:H7, or Cryptosporidium parvum. Alternatively, for juices other than apple juice, you may generically designate "vegetative bacterial pathogens" as your pertinent microorganism if your juice is an acidic juice, i.e., pH of 4.6 or less, no illness outbreaks believed to have been caused by non-bacterial pathogens have been attributed to that juice type, and you are processing your juice using a process that has been validated to achieve a 5-log reduction for Salmonella species, E. coli O157:H7, and Listeria monocytogenes, such as the general process which is discussed in section V.C.5.0 under "Process Validation."

Low-acid juices, such as carrot juice, that are distributed under refrigeration, and are not subject to the Low Acid Canned Foods regulation (21 CFR Part 113) may pose hazards associated with spore forming pathogens, specifically, toxins of non-proteolytic and proteolytic strains of Clostridium botulinum. Control measures for such juices are likely to involve multiple measures, e.g., a combination of a process step to destroy the non-proteolytic spores and measures to ensure that "Keep Refrigerated" labeling is used for the juice if the juice does not receive a treatment sufficient to destroy the proteolytic spores (Destruction of spores of the proteolytic strains requires a more severe heat treatment but germination and growth of these spores may be prevented by keeping the product under refrigeration during its lifecycle. Destruction of spores of the non-proteolytic strains requires a less severe heat treatment, but these spores can germinate and produce toxin even under refrigerated storage conditions) [@nutrition_guidance_2024].

## Previous QMRAs in the domain

One for apples is @frankish_farm_2024 and another one for assessing the initial contamination in apple cider is @duffy_monte_2002 and the potential of growth in @duffy_modeling_2001. One QMRA for apple juice and selecting UV process conditions is @gayan_selection_2014.

## Regarding growth

The literature is mixed but in most cases there is no growth but inactivation instead, so @duffy_modeling_2001 have shown that the behaviour can be simulated with a logistic or a uniform distribution based on the storage temperatures (but they say that overall there was a decline although a small fraction of the time a slight increase was seen)

## Initial concentration

According to @european_food_safety_authority_urgent_2011, out of 5910 of vegetable and fruit samples during the years 2004-2009, only 11 of them were found positive for STEC (0.19%) and non of them corresponded to fruits (n=2774) or juice (n=317) samples. We will assume that the microorganism of interest is *Escherichia coli.* We will define our initial concentration as the concentration of *E. coli* in the fruit juice tank after the juice is extracted from the fruit. According to @gayan_selection_2014 that used the FSO defined for enteric pathogens from the contamination of E. coli O157:H7 of the freshly pressed apple juice before pasteurization must not exceed 10 CFU/ml. Thus, we assume that this concentration can be described by a uniform distribution with minimum and maximum with equal probabilities to be 0 or 1 log~10~ CFU/ml, respectively. It has some variability which is defined in level 0.

```{r}
#| eval: true
#| echo: false
#| include: false
# We first load our libraries
library(tidyverse)
library(biorisk)
```

```{r}
#| eval: false
#| echo: false
logN0 <- Uniform$new("logN0", # A uniform distribution
                 level = 0)$
  map_input("min",
            Constant$new("logN0_min", 0) # with a constant min. value
)$
  map_input ("max",
             Constant$new("logN0_max", 1) # and a constant max. value
)

```

```{r}
#| eval: true
#| echo: true

# The equivalent scenario without variability

logN0 <- Constant$new("logN0", 0)

intercept_pef <- 0.72907

logN0_pef <- Constant$new("logN0_pef", 0 - intercept_pef) # based on the intercept of our initial equation of reductions and energy input

```

## Inactivation using thermal processing

Moving to the next step of the microbial inactivation during thermal processing, we need to define our inactivation model, which in our case is a log-linear primary inactivation model:

$$
\log_{10}N = \log_{10}N_0 - \frac{{\ t}}{{\ D}}
$$ {#eq-primary}

In order to assess the effect of temperature on the *D*-value we will also use a log-linear secondary model:

$$
D = D_{ref} \cdot 10^{\frac{(T_{ref} - T)}{z}}
\quad \text{OR} \quad
\log(D) = \log(D_{ref}) + \frac{(T_{ref} - T)}{z}
$$ {#eq-secondary}

For that we will use a secondary log-linear model that was developed for thermal processing and *E. coli*, as defined from our meta-analysis with a $\log_{10}D_{ref}$ of -0.67 at $T_{ref} = 70^\circ C$, a $\sigma$ of 0.62 and student $t-value$ of 1.97:

In the prediction we could use the worst case scenario i.e., the upper limit of the $\log_{10}D_{ref}$:

$$
log_{10}D_{refupper} = log_{10}D_{ref} + t \cdot sigma
$$

```{r}
#| eval: false
#| echo: false

logDref <- -0.67
t_value <- 1.97
sigma <- 0.62
logDrefupper <- logDref + t_value*sigma
logDreflower <- logDref - t_value*sigma
# Convert from log scale to the original scale
Drefupper <- 10^logDrefupper
Dreflower <- 10^logDreflower
# Print the result
print(Drefupper)
print(Dreflower)
```

```{r}
#| eval: true
#| echo: true

# The equivalent without variability and using the Dref
logDref <- -1.77 #this is the value from Esther for fruit juices and ciders without other additives (26 datapoints and extrapolation the equation is: y = -0.1785x + 10.723 R² = 0.9057)
Dref <- 10^logDref
print(Dref)

```

We also know from [@van_asselt_systematic_2006] that $z = 10.67$. So, let's put the secondary model in the primary model described above (@eq-primary) :

```{r}
#| eval: false
#| echo: false
## Secondary model

#temperature <- Normal$new("temperature", level = 0)$  # Normal pressure level with some variability assigned
  #map_input("mu", Constant$new("temperature_mu", 72))$
 # map_input("sigma", Constant$new("temperature_sigma", 5))


Dref_tp <- Constant$new("Dref_tp", Drefupper)

sec_model_tp <- Dz_model$new("D_tp")$
  map_input("Dref", Dref_tp)$
  map_input("temperature", Constant$new("temperature", 71.111))$
  map_input("z", Constant$new("z_tp", 5.602))$ #this is the value from Esther for fruit juices and ciders without other additives
  map_input("Tref", Constant$new("Tref", 70))
```

```{r}
#| eval: true
#| echo: true

# The equivalent without variability and uncertainty

# Secondary model

Dref_tp <- Constant$new("Dref_tp", Dref)

sec_model_tp <- Dz_model$new("D_tp")$
  map_input("Dref", Dref_tp)$
  map_input("temperature", Constant$new("temperature", 71.111))$
  map_input("z", Constant$new("z_tp", 5.602))$ #this is the value from Esther for fruit juices and ciders without other additives
  map_input("Tref", Constant$new("Tref", 70))
```

And now let's plug our secondary model to the primary one setting the treatment to 20 seconds:

```{r}
t_tp <- Constant$new("t_tp", 0.1) # the treatment time (minutes, 6 seconds)

inactivation_tp <- LogLinInactivation$new("Treatment_tp")$
  map_input("logN0", logN0)$ #We map logN0 to the initial count defined before
  map_input("D", sec_model_tp)$
  map_input("t", t_tp)

```

## Inactivation using HPP

We want to do the same for HPP processing. For that we will use our log-linear model for fruit juices and *E. coli*, as defined from our meta-analysis:

$$
\ LogD = 1.434 -0.000329 \cdot P
$$ {#eq-secondary-pressure}

This model is the same with the one showed above in @eq-secondary but with using pressure instead of temperature. The *z~p~* can be estimated as the negative inverse of the slope i.e., 304 MPa. For the Pref we will use 400 MPa. The treatment pressure *P* is described by a normal distribution with mean 550 MPa and standard deviation 20 MPa (variability i.e., level = 0) (550 MPa for 1 minute is a relevant combination according to Hiperbaric insights). Dref (at the Pref) was estimated as 1.3 minutes from the @eq-secondary-pressure but we assume that is described by a uniform distribution with a minimum of 1 minute and maximum of 4 minutes (variability i.e., level = 0). The treatment time in this case is assumed to be 5 minutes.

Let's implement those changes:

```{r}
#| eval: false
#| echo: false

# Secondary model

pressure <- Normal$new("pressure", level = 0)$  # Normal pressure level with some variability assigned
  map_input("mu", Constant$new("pressure_mu", 550))$
  map_input("sigma", Constant$new("pressure_sigma", 20))

# Dref_hpp <- Uniform$new("Dref_hpp", level = 0)$  # Variability in Dref
  # map_input("min", Constant$new("Dref_hpp_min", 1))$
  # map_input("max", Constant$new("Dref_hpp_max", 4))

sec_model_hpp <- Dz_model$new("D_hpp")$
  map_input("Dref", Constant$new("Dref_hpp", 1.13))$
  map_input("temperature", pressure)$
  map_input("z", Constant$new("z_hpp", 269.7))$
  map_input("Tref", Constant$new("Pref", 400))
```

```{r}
#| eval: true
#| echo: true
# The equivalent without variability

# Secondary model

# Dref_hpp <- Uniform$new("Dref_hpp", level = 0)$  # Variability in Dref
  # map_input("min", Constant$new("Dref_hpp_min", 1))$
  # map_input("max", Constant$new("Dref_hpp_max", 4))

sec_model_hpp <- Dz_model$new("D_hpp")$
  map_input("Dref", Constant$new("Dref_hpp", 1.13))$
  map_input("temperature", Constant$new("pressure_mu", 550))$
  map_input("z", Constant$new("z_hpp", 269.7))$
  map_input("Tref", Constant$new("Pref", 400))
```

```{r}
# t_hpp <- Constant$new("t_hpp", 5) # the treatment time (minutes)

inactivation_hpp <- LogLinInactivation$new("Treatment_hpp")$
  map_input("logN0", logN0)$ #We map logN0 to the initial count defined before
  map_input("D", sec_model_hpp)$
  map_input("t", Constant$new("t_hpp", 1))

```

## Inactivation using PEF processing

For PEF processing we will also define a log-linear primary inactivation model, but using the energy input ($E_i$ in kJ/L) instead:

$$
\log_{10}N = \log_{10}N_0 - \frac{E_i}{D_{E_i}}
$$ {#eq-primary-energy}

Here we will not define a secondary model since the effect of the energy input level is already integrated on the inactivation, replacing the time parameter. So, we move directly to the primary model, and we will use the D value, as determined from the log-linear fitting, using the model fitted for fruit juices and *E. coli*. The *D* was estimated as 50.4 kJ/L and thus we used a uniform distribution for that with a minimum of 60 kJ/L and a maximum of 80 kJ/L. According to @aganovic_environmental_2022, the energy input levels applied for the treatment of heat-sensitive liquids are usually between 80-120 kJ/kg. Thus we selected as applied energy input the 120 kJ/L or for this case (assuming that the density of a fruit juice is approximately 1 $kg/L$). For this, we assume that the applied energy input can be described by a normal distribution with a mean of 120 kJ/L and a standard deviation of 5 kJ/L.

nactivation_pef \<- LogLinInactivation\$new("Treatment_pef")\$

map_input("logN0", logN0)\$ #We map logN0 to the initial count defined before

map_input("D", inactivation_model_pef)\$

map_input("t", energy_pef)

```{r}
#| eval: false
#| echo: false
# D_pef <- Uniform$new("D_pef", level = 0)$  # Variability in D_pef
  # map_input("min", Constant$new("D_pef_min", 60))$
  # map_input("max", Constant$new("D_pef_max", 80))

energy_pef <- Normal$new("energy_pef", level = 0)$  # Normal energy input level with some variability assigned
  map_input("mu", Constant$new("energy_mu", 120))$
  map_input("sigma", Constant$new("energy_sigma", 2))


inactivation_pef <- LogLinInactivation$new("Treatment_pef")$
  map_input("logN0", logN0_pef)$ #We map logN0 to the intercept
  map_input("D", Constant$new("D_pef", 40.37832))$
  map_input("t", energy_pef)

```

```{r}
#| eval: true
#| echo: true

energy_pef <- Constant$new("energy_pef", 120)

inactivation_pef <- LogLinInactivation$new("Treatment_pef")$
  map_input("logN0", logN0_pef)$ #We map logN0 to the logN0 with the intercept
  map_input("D", Constant$new("D_pef", 40.37832))$
  map_input("t", energy_pef)

```

## Summary of all inactivation models

::: panel-tabset
#### Thermal processing inactivation model

```{r}
#| eval: false
#| echo: false
plot_model(inactivation_tp)
```

![](inactivation_tp.png)

#### HPP inactivation model

```{r}
#| eval: false
#| echo: false
plot_model(inactivation_hpp)
```

![](inactivation_hpp.png)

#### PEF inactivation model

```{r}
#| eval: false
#| echo: false
plot_model(inactivation_pef)
```

![](inactivation_pef.png)
:::

# Let's visualize what we have done so far with the inactivation models through a density plot after performing 1000 simulations:

::: panel-tabset
#### Thermal processing model

```{r}
#| eval: false
#| echo: false
inactivation_tp$simulate(1000)
inactivation_tp$density_plot()

```

#### HPP inactivation model

```{r}
#| eval: false
#| echo: false
inactivation_hpp$simulate(1000)
inactivation_hpp$density_plot()

```

#### PEF inactivaiton model

```{r}
#| eval: false
#| echo: false
inactivation_pef$simulate(1000)
inactivation_pef$density_plot()

```
:::

## Growth during storage

In Combase, all models for *E. coli* and juices/beverages category all models show inactivation and not growth during storage except for one study showing first an increase in the microbial population of 1 log CFU/ml within the first 2 days and then a decrease [@zhao_fate_1993].

In this section, we will describe the microbial growth during storage using the exponential growth model with stationary phase (bilinear model):

$$
\log N = 
\begin{cases} 
\log N_0 + \mu \cdot t & \text{if } \log N_0 + \mu \cdot t < \log N_{\text{max}} \\
\log N_{\text{max}} & \text{otherwise}
\end{cases}
$$ {#eq-expon_growth}

with the growth rate given by the Ratkowsky model:

$$
\sqrt{\mu} = b \cdot (T - T_{\text{min}}) \quad (\sqrt{\frac{\log}{h}})
$$

As above, we first need to define the secondary model. The Ratkowsky model has three inputs: treatment temperature, *T*~min~, and *b*. For the temperature, we assign a normal distribution that represents uncertainty (level = 1) with expected value (mean) of 6.35 ºC (we define the metric units) and a standard deviation of 2.83 ºC (we define the metric units) .

The typical shelf life of refrigerated juices range between 28 and 45 days @esteve_refrigerated_2007, so we assumed a uniform distribution with these minimum and maximum values. But the data of Schaffner were with values only below 30 days, they removed the above this limit.

```{r}
#| eval: true
#| echo: true
# This is based on Duffy and Schaffner 2001
# They are probability distributions to simulate the change of STEC in ciders during storage where there is an overall decline although a small fraction of the time a slight increase might be seen

# For ideal refrigeration (4 to 5 ºC)

ideal_storage <- LogisticDistr$new("ideal_storage", level = 0)$
  map_input("location", Constant$new("location_ideal_storage", -0.061))$
  map_input("scale", Constant$new("scale_ideal_storage", 0.13))

# For temperature abuse (6 to 10 ºC)

abuse_storage <- LogisticDistr$new("abuse_storage", level = 0)$
  map_input("location", Constant$new("location_abuse_storage", -0.0982))$
  map_input("scale", Constant$new("scale_abuse_storage", 0.23))

# Let's define the storage time

stor_time <- Uniform$new("Storage time")$
  map_input("min", Constant$new("t_min", 28))$
  map_input("max", Constant$new("t_max", 45))

# Let's multiply these two to have the combined effect over time
# Use ElementTimes to multiply these distributions to get the combined effect
change_storage_ideal <- ElementTimes$new("change_storage_ideal")$
  map_input("a", ideal_storage)$
  map_input("b", stor_time)

change_storage_abuse <- ElementTimes$new("change_storage_abuse")$
  map_input("a", abuse_storage)$
  map_input("b", stor_time)

# And let's add this to our previous logN values after the inactivation steps

tp_ideal_storage <- ElementPlus$new("after_tp_storage")$
  map_input("a", inactivation_tp)$
  map_input("b", change_storage_ideal)

hpp_ideal_storage <- ElementPlus$new("after_hpp_storage")$
  map_input("a", inactivation_hpp)$
  map_input("b", change_storage_ideal)

pef_ideal_storage <- ElementPlus$new("after_pef_storage")$
  map_input("a", inactivation_pef)$
  map_input("b", change_storage_ideal)

tp_abuse_storage <- ElementPlus$new("after_tp_storage")$
  map_input("a", inactivation_tp)$
  map_input("b", change_storage_abuse)

hpp_abuse_storage <- ElementPlus$new("after_hpp_storage")$
  map_input("a", inactivation_hpp)$
  map_input("b", change_storage_abuse)

pef_abuse_storage <- ElementPlus$new("after_pef_storage")$
  map_input("a", inactivation_pef)$
  map_input("b", change_storage_abuse)

```

```{r}
#| eval: false
#| echo: false
temp_distrib <- Normal$new("temp_distrib",
                           level = 1)$ # a normal distribution
  map_input("mu", 
            Constant$new("mu_temp_distrib", 6.35) # with a constant mean
)$
  map_input("sigma",
            Constant$new("sd_temp_distrib", 2.83) # and a constant variance
)
```

Then, we define the Ratkowsky model, mapping the temperature to the element we just defined. In this case, we assume no variability or uncertainty in the model parameters, and the *b* is assumed to be 0.014 and *T~min~* to be 1.6.

```{r}
#| eval: false
#| echo: false
mu_distrib <- Ratkowsky_model$new("mu_distrib")$ #the Ratkowsky seondary model
  map_input("b",
            Constant$new("b_distrib", 0.0144) #with constant b
)$
  map_input("Tmin",
            Constant$new("Tmin_distrib", 1.6) # and constant Tmin
)$
  map_input("temperature",
            temp_distrib
)

```

```{r}
#| eval: false
#| echo: false
plot_model(mu_distrib)
```

The scheme of the secondary growth model as we defined it:

![](C:/Users/pampo002/R/mu_distribution.png)

Now, we can go back to the primary growth model and integrate our secondary model there. As mentioned above, the model to be used is the **ExponentialGrowthNmax** (@eq-expon_growth). The only input left to assign is the storage time, for which we will assume an exponential distribution with rate parameter 1/29.

```{r}
#| eval: false
#| echo: false
time_distrib <- Exponential$new("time_distrib")$ # an exponential distribution
  map_input("rate",
            Constant$new("rate_time_distrib", 1/29)# with constant rate parameter
)
```

Now, we have everything and we will implement the **ExponentialGrowthNmax** as our primary model. For the treatment time, we will use the storage time that we just defined. The growth rate $\mu$ is already mapped to the output of the Ratkowsky model. Then, the initial concentration at storage needs to be mapped to the output of the inactivation model (to be our reference logN0 for this stage). Finally, we will define a constant *N~max~* of 8 log CFU/g.

```{r}
#| eval: false
#| echo: false

# Define a function to create an ExponentialGrowthNmax object with mapped inputs
# This function takes two arguments: 'name' and 'logN0_input'
create_growth_distrib <- function(name, logN0_input) {
  ExponentialGrowthNmax$new(name)$  # Create a new ExponentialGrowthNmax object with the given name
    map_input("t", time_distrib)$   # Map the 't' input to the 'time_distrib' object
    map_input("mu", mu_distrib)$    # Map the 'mu' input to the 'mu_distrib' object
    map_input("logN0", logN0_input)$ # Map the 'logN0' input to the provided 'logN0_input' argument
    map_input("logNmax", Constant$new("logNmax", 8)) # Map the 'logNmax' input to a constant value of 8
}

# Use the function to create three different growth distribution objects

# Create 'growth_distrib_tp' by calling the function with 'growth_distrib' name and 'inactivation_tp' for logN0
growth_distrib_tp <- create_growth_distrib("growth_distrib", inactivation_tp)

# Create 'growth_distrib_hpp' by calling the function with 'growth_distrib' name and 'inactivation_hpp' for logN0
growth_distrib_hpp <- create_growth_distrib("growth_distrib", inactivation_hpp)

# Create 'growth_distrib_pef' by calling the function with 'growth_distrib' name and 'inactivation_pef' for logN0
growth_distrib_pef <- create_growth_distrib("growth_distrib", inactivation_pef)


```

```{r}
#| eval: false
#| echo: false

# Create a list of the models to be plotted
growth_distrib_obj <- list(growth_distrib_tp, growth_distrib_hpp, growth_distrib_pef)
```

```{r}
#| eval: false
#| echo: false
# Iterate over each model in the list and plot it
lapply(growth_distrib_obj, plot_model)

```

# Summary of Initial concentration + Inactivation + Growth during distribution

::: panel-tabset
#### Thermal processing inactivation model

![](growth_distribution_tp.png)

#### HPP inactivation model

![](growth_distribution_hpp.png)

#### PEF inactivation model

![](growth_distribution_pef.png)
:::

## Consumer phase {#sec-consumer_phase}

The next step is to convert the microbial concentration (in log CFU/g) to the microbial dose consumed. For this, we will use the **Concentration2Dose** element. This element considers the fact that the dose is a sampling process (i.e., the output is a discrete number of cells).

We have two inputs for the dose response model i.e., the microbial exposure at exposure and the serving size. For the latter, we use a uniform distribution that represents variability (level = 0). For the microbial concentration, we map the output of the growth element from above.

```{r}
#| eval: false
#| echo: false

# Define the serving_size object
serving_size <- Uniform$new("size", level = 0)$  # Create a new Uniform object named 'size'
  map_input("min", Constant$new("min_size", 200))$  # Map the 'min' input to a constant value of 200
  map_input("max", Constant$new("max_size", 300))  # Map the 'max' input to a constant value of 500
```

```{r}
#| eval: true
#| echo: true

#The equivalent without variability

# Define the serving_size object
serving_size <- Constant$new("serving_size", 200)  # Map the input to a constant value of 200
```

```{r}
#| eval: false
#| echo: false
# Define a function to create a Concentration2Dose object with mapped inputs
# This function takes two arguments: 'name' and 'logN_input'
# @param name The name of the Concentration2Dose object
# @param logN_input The input object to map to the 'logN' parameter
# @return A Concentration2Dose object with the specified mappings

create_consumer_dose <- function(name, logN_input) {
  Concentration2Dose$new(name)$  # Create a new Concentration2Dose object with the given name
    map_input("logN", logN_input)$  # Map the 'logN' input to the provided 'logN_input' argument
    map_input("size", serving_size)  # Map the 'size' input to the 'serving_size' object
}

# Use the function to create three different consumer dose objects

# Create 'consumer_dose_tp' by calling the function with 'dose' name and 'growth_distrib_tp' for logN
consumer_dose_tp <- create_consumer_dose("consumer_dose_tp", inactivation_tp)

# Create 'consumer_dose_hpp' by calling the function with 'dose' name and 'growth_distrib_hpp' for logN
consumer_dose_hpp <- create_consumer_dose("consumer_dose_hpp", inactivation_hpp)

# Create 'consumer_dose_pef' by calling the function with 'dose' name and 'growth_distrib_pef' for logN
consumer_dose_pef <- create_consumer_dose("consumer_dose_pef", inactivation_pef)

inactivation_tp$point_estimate()
inactivation_hpp$point_estimate()
inactivation_pef$point_estimate()
consumer_dose_tp$point_estimate()
consumer_dose_hpp$point_estimate()
consumer_dose_pef$point_estimate()

```

```{r}
#| eval: true
#| echo: true
# Here is the equivalent if we simulate the change during distribution (ideal)

# Define a function to create a Concentration2Dose object with mapped inputs
# This function takes two arguments: 'name' and 'logN_input'
# @param name The name of the Concentration2Dose object
# @param logN_input The input object to map to the 'logN' parameter
# @return A Concentration2Dose object with the specified mappings

create_consumer_dose <- function(name, logN_input) {
  Concentration2Dose$new(name)$  # Create a new Concentration2Dose object with the given name
    map_input("logN", logN_input)$  # Map the 'logN' input to the provided 'logN_input' argument
    map_input("size", serving_size)  # Map the 'size' input to the 'serving_size' object
}

# Use the function to create three different consumer dose objects

# Create 'consumer_dose_tp' by calling the function with 'dose' name and 'growth_distrib_tp' for logN
consumer_dose_tp <- create_consumer_dose("consumer_dose_tp", tp_ideal_storage)

# Create 'consumer_dose_hpp' by calling the function with 'dose' name and 'growth_distrib_hpp' for logN
consumer_dose_hpp <- create_consumer_dose("consumer_dose_hpp", hpp_ideal_storage)

# Create 'consumer_dose_pef' by calling the function with 'dose' name and 'growth_distrib_pef' for logN
consumer_dose_pef <- create_consumer_dose("consumer_dose_pef", pef_ideal_storage)

inactivation_tp$point_estimate()
inactivation_hpp$point_estimate()
inactivation_pef$point_estimate()
ideal_storage$point_estimate()
stor_time$point_estimate()
change_storage_ideal$point_estimate()
tp_ideal_storage$point_estimate()
hpp_ideal_storage$point_estimate()
pef_ideal_storage$point_estimate()
consumer_dose_tp$point_estimate()
consumer_dose_hpp$point_estimate()
consumer_dose_pef$point_estimate()

```

```{r}
#| eval: false
#| echo: false
# Here is the equivalent if we simulate the change during distribution (abuse)

# Define a function to create a Concentration2Dose object with mapped inputs
# This function takes two arguments: 'name' and 'logN_input'
# @param name The name of the Concentration2Dose object
# @param logN_input The input object to map to the 'logN' parameter
# @return A Concentration2Dose object with the specified mappings

create_consumer_dose <- function(name, logN_input) {
  Concentration2Dose$new(name)$  # Create a new Concentration2Dose object with the given name
    map_input("logN", logN_input)$  # Map the 'logN' input to the provided 'logN_input' argument
    map_input("size", serving_size)  # Map the 'size' input to the 'serving_size' object
}

# Use the function to create three different consumer dose objects

# Create 'consumer_dose_tp' by calling the function with 'dose' name and 'growth_distrib_tp' for logN
consumer_dose_tp <- create_consumer_dose("consumer_dose_tp", tp_abuse_storage)

# Create 'consumer_dose_hpp' by calling the function with 'dose' name and 'growth_distrib_hpp' for logN
consumer_dose_hpp <- create_consumer_dose("consumer_dose_hpp", hpp_abuse_storage)

# Create 'consumer_dose_pef' by calling the function with 'dose' name and 'growth_distrib_pef' for logN
consumer_dose_pef <- create_consumer_dose("consumer_dose_pef", pef_abuse_storage)

inactivation_tp$point_estimate()
inactivation_hpp$point_estimate()
inactivation_pef$point_estimate()
consumer_dose_tp$point_estimate()
consumer_dose_hpp$point_estimate()
consumer_dose_pef$point_estimate()

```

## Risk characterization

For this stage, we need first to define a dose-response model. We will use the exponential dose-response model:

$$ P_{\text{ill}} = 1 - e^{(-r \cdot dose)} $$

Another approach would be to use the modified Beta-Binomial model of @cassin_quantitative_1998 (with $alpha = 0.267$ and $beta = 229.2928$), as they did in @frankish_farm_2024: $$ P_{\text{ill}} = 1 - \left(1 + \frac{D}{\beta}\right)^{\alpha} $$

According to an RIVM study $r = 9.3 \cdot 10^{-3}$ for children and $5.1 \cdot 10^{-3}$ for adults (RIVM reference). Taking the worst-case scenario (children) and assuming a constant pathogen-host survival probability the equation is:

$$ P_{\text{ill}} = 1 - e^{(-9.3 \cdot 10^{-3} \cdot dose)} $$for children and:

$$ P_{\text{ill}} = 1 - e^{(-5.1 \cdot 10^{-3} \cdot dose)} $$

for adults, respectively

where the dose is the output of the @sec-consumer_phase section

```{r}
# Define a function to create a DoseResponse_Exponential object with mapped inputs
# This function takes two arguments: 'name' and 'dose_input'
# @param name The name of the DoseResponse_Exponential object
# @param dose_input The input object to map to the 'dose' parameter
# @return A DoseResponse_Exponential object with the specified mappings

create_pill <- function(name, dose_input, r_value) {
  DoseResponse_Exponential$new(name)$  # Create a new DoseResponse_Exponential object with the given name
    map_input("r", Constant$new("r_dr", r_value))$  # Map the 'r' input to the given r value
    map_input("dose", dose_input)  # Map the 'dose' input to the provided 'dose_input' argument
}

# Create the Pill objects for children and adults separately
Pill_tp_adults <- create_pill("Pill_tp_adults", consumer_dose_tp, 5.1e-3)
Pill_hpp_adults <- create_pill("Pill_hpp_adults", consumer_dose_hpp, 5.1e-3)
Pill_pef_adults <- create_pill("Pill_pef_adults", consumer_dose_pef, 5.1e-3)
Pill_pef_children <- create_pill("Pill_pef_children", consumer_dose_pef, 9.3e-3)
Pill_tp_children <- create_pill("Pill_tp_children", consumer_dose_tp, 9.3e-3)
Pill_hpp_children <- create_pill("Pill_hpp_children", consumer_dose_hpp, 9.3e-3)


# Calculate the median values for each dose response object for both children and adults

pill_median_tp_adults <- Pill_tp_adults$point_estimate()
pill_median_hpp_adults <- Pill_hpp_adults$point_estimate()
pill_median_pef_adults <- Pill_pef_adults$point_estimate()
pill_median_tp_children <- Pill_tp_children$point_estimate()
pill_median_hpp_children <- Pill_hpp_children$point_estimate()
pill_median_pef_children <- Pill_pef_children$point_estimate()



print(pill_median_tp_adults)
print(pill_median_hpp_adults)
print(pill_median_pef_adults)
print(pill_median_tp_children)
print(pill_median_hpp_children)
print(pill_median_pef_children)



```

Then, we can estimate the number of cases. For that, **biorisk** includes the **Pill2Cases_N** element to convert from probability of illness to number of cases, assuming that the number of cases can be described by a binomial distribution as shown below:

$$ \text{cases} = \text{Binomial}(n = \text{servings}, p = P_{\text{ill}}) $$According to the European Fruit Juice Association 2019 Liquid Fruit Market Report (https://aijn.h5mag.com/aijn2019report/the_fruit_juice_industry_overall_fruit_juice_consumption), 9.1 billion litres of fruit juice were consumed in 2017. If we convert this number to serving of 200 ml, we would have approximately $4.6*10^{10}$ servings. For our information the mean of the binomial distribution could also estimated using $4.6*10^{10}$ servings multiplied with the median value of the $P_{\text{ill}}$ that was previously defined:

$$\mu_{\text{mean}} = 4.6 \cdot 10^{12} \cdot P_{\text{ill(median)}}$$

```{r}
#| eval: true

servings_adults <- 0.8*4.6e10
servings_children <- 0.2*4.6e10

# Calculate the mean cases values by multiplying each combined median value by 4.6e10
cases_mean_tp <- (pill_median_tp_children * servings_children) + (pill_median_tp_adults * servings_adults)
cases_mean_hpp <- (pill_median_hpp_children * servings_children) + (pill_median_hpp_adults * servings_adults)
cases_mean_pef <- (pill_median_pef_children * servings_children) + (pill_median_pef_adults * servings_adults)

# Print the cases_mean values
print(cases_mean_tp)
print(cases_mean_hpp)
print(cases_mean_pef)

```

This element considers for each Monte Carlo iteration that the **nservings** have the same probability of illness. On the other hand, the element **Pill2Cases_1** considers a single serving per Pill. In this case, we will make the calculations per $10^{12}$ servings.

```{r}
#| eval: true

# Define a function to create a Pill2Cases_N object with mapped inputs
# This function takes two arguments: 'name' and 'pill_input'
# @param name The name of the Pill2Cases_N object
# @param pill_input The input object to map to the 'Pill' parameter
# @param servings_input The input object to map to the 'Pill' parameter
# @return A Pill2Cases_N object with the specified mappings

create_cases <- function(name, pill_input, servings_input) {
  Pill2Cases_N$new(name)$  # Create a new Pill2Cases_N object with the given name
    map_input("Pill", pill_input)$  # Map the 'Pill' input to the provided 'pill_input' argument
    map_input("servings", Constant$new("n_servings", servings_input))  # Map the 'servings' input to the corresponding value for adults and children
}

# Create the cases objects for each combined median value
cases_tp_adults <- create_cases("cases_tp_adults", Pill_tp_adults, 
servings_adults)
cases_hpp_adults <- create_cases("cases_hpp_adults", Pill_hpp_adults, servings_adults)
cases_pef_adults <- create_cases("cases_pef_adults", Pill_pef_adults, servings_adults)
cases_tp_children <- create_cases("cases_tp_children", Pill_tp_children, servings_children)
cases_hpp_children <- create_cases("cases_hpp_children", Pill_hpp_children, servings_children)
cases_pef_children <- create_cases("cases_pef_children", Pill_pef_children, servings_children)

# Calculate and print the number of cases for each Pill object
cases_tp_adults_value <- cases_tp_adults$point_estimate()
cases_hpp_adults_value <- cases_hpp_adults$point_estimate()
cases_pef_adults_value <- cases_pef_adults$point_estimate()
cases_tp_children_value <- cases_tp_children$point_estimate()
cases_hpp_children_value <- cases_hpp_children$point_estimate()
cases_pef_children_value <- cases_pef_children$point_estimate()

print(cases_tp_adults_value)
print(cases_hpp_adults_value)
print(cases_pef_adults_value)
print(cases_tp_children_value)
print(cases_hpp_children_value)
print(cases_pef_children_value)

```

# Summary of Initial concentration + Inactivation + Growth during distribution + Risk characterization (full model)

::: panel-tabset
#### Thermal processing model (adults)

```{r}
#| eval: false
#| echo: false 
plot_model(cases_tp_adults)


```

![](cases_tp.png)

#### HPP model (adults)

```{r}
#| eval: false
#| echo: false 
plot_model(cases_hpp_adults)
```

![](cases_hpp.png)

#### PEF model (adults)

```{r}
#| eval: false
#| echo: false 
plot_model(cases_pef_adults)

```

![](cases_pef.png)
:::

::: panel-tabset
#### Thermal processing model (children)

```{r}
#| eval: false
#| echo: false 
plot_model(cases_tp_children)


```

![](cases_tp.png)

#### HPP model (children)

```{r}
#| eval: false
#| echo: false 
plot_model(cases_hpp_children)
```

![](cases_hpp.png)

#### PEF model(children)

```{r}
#| eval: false
#| echo: false 
plot_model(cases_pef_children)

```

![](cases_pef.png)
:::

# Simulation and visualization

```{r}
#| eval: false
#| echo: false

# Let's check our dependencies to see if we made any mistake in the dependencies of the model, regarding the consistency of the variable names.

cases_tp_adults$check_input_types(recursive = TRUE)
cases_hpp_adults$check_input_types(recursive = TRUE)
cases_pef_adults$check_input_types(recursive = TRUE)
cases_tp_children$check_input_types(recursive = TRUE)
cases_hpp_children$check_input_types(recursive = TRUE)
cases_pef_children$check_input_types(recursive = TRUE)

# Warning: In element Pill: the element expects discrete for input dose. Got continuous instead from dose. We cannot have 321.1 CFU but we made this simplification, this would work if we would take the discrete models of the other case study


```

## Simulation as a 1D Monte Carlo

Then, we continue with our 1D Monte Carlo:

```{r}
#| eval: false
#| echo: false
cases_tp_adults$simulate(100000, seed = 241)
cases_hpp_adults$simulate(100000, seed = 241)
cases_pef_adults$simulate(100000, seed = 241)
cases_tp_children$simulate(100000, seed = 241)
cases_hpp_children$simulate(100000, seed = 241)
cases_pef_children$simulate(100000, seed = 241)
```

We can now visualize the number of cases per $10^{12}$ servings, as a histogram. We will use the log transform due to the heavy tail, but this removes also the 0s i.e., the simulations that lead to 0 cases. Therefore we also need to know how many are the 0s in our simulations (it's in the warning created). We will also add a discrete line with the approximate as estimated before. (Note that this is quite biased with respect to the histogram. The reasons for this is the use of asymmetric distributions and the nonlinear models).

```{r}
#| eval: false
#| echo: false
cases_tp_adults$histogram(add_discrete = TRUE) + scale_x_log10()
cases_hpp_adults$histogram(add_discrete = TRUE) + scale_x_log10()
cases_pef_adults$histogram(add_discrete = TRUE) + scale_x_log10()
cases_tp_children$histogram(add_discrete = TRUE) + scale_x_log10()
cases_hpp_children$histogram(add_discrete = TRUE) + scale_x_log10()
cases_pef_children$histogram(add_discrete = TRUE) + scale_x_log10()

```

Then, we can also visualize other elements such as the microbial concentration at the end of storage as a density plot (again with a discrete dashed line, "TRUE").

```{r}
#| eval: false
#| echo: false
growth_distrib_tp$density_plot(TRUE)
growth_distrib_hpp$density_plot(TRUE)
growth_distrib_pef$density_plot(TRUE)
```

Now we will take a look at the quantiles

```{r}
#| eval: false
#| echo: false
quantile_table(cases_tp_adults, chosen = c("cases", "Pill", "dose", "Treatment_tp"),
               probs = c(0.50, 0.90, 0.99))

quantile_table(cases_hpp_adults, chosen = c("cases", "Pill", "dose", "Treatment_hpp"),
               probs = c(0.50, 0.90, 0.99))

quantile_table(cases_pef_adults, chosen = c("cases", "Pill", "dose", "Treatment_pef"),
               probs = c(0.50, 0.90, 0.99))

quantile_table(cases_tp_children, chosen = c("cases", "Pill", "dose", "Treatment_tp"),
               probs = c(0.50, 0.90, 0.99))

quantile_table(cases_hpp_children, chosen = c("cases", "Pill", "dose", "Treatment_hpp"),
               probs = c(0.50, 0.90, 0.99))

quantile_table(cases_pef_children, chosen = c("cases", "Pill", "dose", "Treatment_pef"),
               probs = c(0.50, 0.90, 0.99))

```

It would also be nice to monitor the variation of the microbial concentration on each step. We will do this with three ways namely, box plot, violin plot and density plot.

::: panel-tabset
#### Box plot

```{r}
#| eval: false
#| echo: false
#| label: plot-E
#| fig-height: 8
#| fig-width: 12

# List of cases objects
inactivation_obj <- list(inactivation_tp, inactivation_hpp, inactivation_pef)

# Names of the processing methods
processing_methods <- c("Thermal processing", "High Pressure Processing", "Pulsed Electric Fields")

# General function to plot outputs for a given inactivation object and processing method
plot_case_outputs <- function(inactivation_obj, method) {
  plot_outputs(inactivation_obj, chosen = c("logN0", "Treatment_tp", "Treatment_hpp", "Treatment_pef")) +
    ggtitle(method)
}

# Use mapply to plot the outputs and print each plot
plots <- mapply(function(inactivation_obj, method) {
  p <- plot_case_outputs(inactivation_obj, method)
  print(p)
}, inactivation_obj, processing_methods)

#1 Thermal processing
#2 High Pressure Processing
#3 PEF processing


```

#### Violin plot

```{r}
#| eval: false
#| echo: false
# List of inactivation objects
inactivation_obj <- list(inactivation_tp, inactivation_hpp, inactivation_pef)

# Names of the processing methods
processing_methods <- c("Thermal processing", "High Pressure Processing", "Pulsed Electric Fields")

# General function to plot outputs for a given inactivation object and processing method
plot_case_outputs <- function(inactivation_obj, method) {
  plot_outputs(inactivation_obj, chosen = c("logN0", "Treatment_tp", "Treatment_hpp", "Treatment_pef"), type = "violin") +
    ggtitle(method)
}

# Use mapply to plot the outputs and print each plot
plots <- mapply(function(inactivation_obj, method) {
  p <- plot_case_outputs(inactivation_obj, method)
  print(p)
}, inactivation_obj, processing_methods)

```

#### Density plot

```{r}
#| eval: false
#| echo: false
# List of inactivation objects
inactivation_obj <- list(inactivation_tp, inactivation_hpp, inactivation_pef)

# Names of the processing methods
processing_methods <- c("Thermal processing", "High Pressure Processing", "Pulsed Electric Field")

# General function to plot outputs for a given inactivation object and processing method
plot_case_outputs <- function(inactivation_obj, method) {
  plot_outputs(inactivation_obj, chosen = c("logN0", "Treatment_tp", "Treatment_hpp", "Treatment_pef"), type = "density") +
    ggtitle(method)
}

# Use mapply to plot the outputs and print each plot
plots <- mapply(function(inactivation_obj, method) {
  p <- plot_case_outputs(inactivation_obj, method)
  print(p)
}, inactivation_obj, processing_methods)

```
:::

Let's perform also a sensitiviy analysis for the overall model (**cases**):

```{r}
#| eval: false
#| echo: false
tornado_plot(cases_tp_adults)
tornado_plot(cases_hpp_adults)
tornado_plot(cases_pef_adults)
tornado_plot(cases_tp_children)
tornado_plot(cases_hpp_children)
tornado_plot(cases_pef_children)
```

## Simulation as a 2D Monte Carlo

For the 2D-MC simulation we need two inputs, the number of simulations for level 0 (variability) and the number of simulations for level 1 (uncertainty). We will use 1000 iterations for variability and 100 for uncertainty. We will visualize the results for growth distribution with a density plot that compares the distribution from the variability (blue) with the distribution including all sources of variation (variability & uncertainty)(grey). Also, we will visualize the cumulative distribution where the line represents the level 0 (variability) and the ribbon the additional variation due to the uncertainty level.

```{r}
#| eval: false
#| echo: false
cases_tp_adults$simulate_2D(1000, 100, seed = 792)
cases_hpp_adults$simulate_2D(1000, 100, seed = 792)
cases_pef_adults$simulate_2D(1000, 100, seed = 792)
cases_tp_children$simulate_2D(1000, 100, seed = 792)
cases_hpp_children$simulate_2D(1000, 100, seed = 792)
cases_pef_children$simulate_2D(1000, 100, seed = 792)

inactivation_tp$density_plot()
inactivation_tp$density_plot_2D()
inactivation_hpp$density_plot()
inactivation_hpp$density_plot_2D()
inactivation_pef$density_plot()
inactivation_pef$density_plot_2D()
inactivation_tp$cummulative_plot()
inactivation_tp$cummulative_plot_2D()
inactivation_hpp$cummulative_plot()
inactivation_hpp$cummulative_plot_2D()
inactivation_pef$cummulative_plot()
inactivation_pef$cummulative_plot_2D()

```

And the same for the cases for adults:

```{r}
#| eval: false
#| echo: false
cases_tp_adults$density_plot()
cases_tp_adults$density_plot_2D()
cases_hpp_adults$density_plot()
cases_hpp_adults$density_plot_2D()
cases_pef_adults$density_plot()
cases_pef_adults$density_plot_2D()
cases_tp_adults$cummulative_plot()
cases_tp_adults$cummulative_plot_2D()
cases_hpp_adults$cummulative_plot()
cases_hpp_adults$cummulative_plot_2D()
cases_pef_adults$cummulative_plot()
cases_pef_adults$cummulative_plot_2D()


```

And for children:

```{r}
#| eval: false
#| echo: false
cases_tp_children$density_plot()
cases_tp_children$density_plot_2D()
cases_hpp_children$density_plot()
cases_hpp_children$density_plot_2D()
cases_pef_children$density_plot()
cases_pef_children$density_plot_2D()
cases_tp_children$cummulative_plot()
cases_tp_children$cummulative_plot_2D()
cases_hpp_children$cummulative_plot()
cases_hpp_children$cummulative_plot_2D()
cases_pef_children$cummulative_plot()
cases_pef_children$cummulative_plot_2D()


```

And our quantiles, as we did before. In this case, the quantiles are calculated both under level 0 (variability) and over the complete model (variability & uncertainty).

```{r}
#| eval: false
#| echo: false

quantile_table_2D(cases_tp_adults, chosen = c("cases_tp_adults", "Pill_tp_adults", "consumer_dose_tp"),
               probs = c(0.50, 0.90, 0.99))

quantile_table_2D(cases_hpp_adults, chosen = c("cases_hpp_adults", "Pill_hpp_adults", "consumer_dose_hpp"),
               probs = c(0.50, 0.90, 0.99))

quantile_table_2D(cases_pef_adults, chosen = c("cases_pef_adults", "Pill_pef_adults", "consumer_dose_pef"),
               probs = c(0.50, 0.90, 0.99))

quantile_table_2D(cases_tp_children, chosen = c("cases_tp_children", "Pill_tp_children", "consumer_dose_tp"),
               probs = c(0.50, 0.90, 0.99))

quantile_table_2D(cases_hpp_children, chosen = c("cases_hpp_children", "Pill_hpp_children", "consumer_dose_hpp"),
               probs = c(0.50, 0.90, 0.99))

quantile_table_2D(cases_pef_children, chosen = c("cases_pef_children", "Pill_pef_children", "consumer_dose_pef"),
               probs = c(0.50, 0.90, 0.99))


```
